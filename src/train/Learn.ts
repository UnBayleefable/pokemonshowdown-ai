import * as tf from "@tensorflow/tfjs";
import {ExperienceConfig, LearnConfig} from "../config/types";
import {BatchTensorExperience} from "../game/experience/tensor";
import {Metrics} from "../model/worker/Metrics";
import {intToChoice} from "../psbot/handlers/battle/agent";

/**
 * Encapsulates the learning step of training, where the model is updated based
 * on experience generated by rollout games.
 */
export class Learn {
    /** Metrics logger. */
    private readonly metrics = Metrics.get(`${this.name}/learn`);
    /** Used for calculating gradients. */
    private readonly optimizer = tf.train.sgd(this.config.learningRate);
    /** Collection of trainable variables in the model. */
    private readonly variables = this.model.trainableWeights.map(
        w => w.read() as tf.Variable,
    );
    /** Used for logging inputs during loss calcs. */
    private readonly hookLayers: readonly tf.layers.Layer[] =
        this.model.layers.filter(l =>
            ["Dense", "SetAttention", "SetMultiHeadAttention"].includes(
                l.getClassName(),
            ),
        );

    /**
     * Creates a Learn object.
     *
     * @param name Name of the training run for logging.
     * @param model Model to train.
     * @param targetModel Model for computing TD targets. Can be set to the same
     * model to disable target model mechanism.
     * @param config Learning config.
     * @param expConfig Experience config for computing TD targets.
     */
    public constructor(
        public readonly name: string,
        private readonly model: tf.LayersModel,
        private readonly targetModel: tf.LayersModel,
        private readonly config: LearnConfig,
        private readonly expConfig: ExperienceConfig,
    ) {
        // Log initial weights.
        for (const weights of this.variables) {
            if (weights.size === 1) {
                const weightScalar = weights.asScalar();
                this.metrics?.scalar(
                    `${weights.name}/weights`,
                    weightScalar,
                    0,
                );
                tf.dispose(weightScalar);
            } else {
                this.metrics?.histogram(`${weights.name}/weights`, weights, 0);
            }
        }
    }

    /**
     * Performs a single batch update step.
     *
     * @param step Step number for logging.
     * @param batch Batch to train on.
     * @returns The loss for this batch.
     */
    public step(step: number, batch: BatchTensorExperience): tf.Scalar {
        return tf.tidy(() => {
            const preStep = process.hrtime.bigint();
            const storeBatchMetrics = step % this.config.metricsInterval === 0;

            const target = this.calculateTarget(
                batch.reward,
                batch.nextState,
                batch.done,
            );

            const hookedInputs: {[name: string]: tf.Tensor1D[]} = {};
            if (storeBatchMetrics) {
                for (const layer of this.hookLayers) {
                    // Note: Call hook is wrapped in tf.tidy() so tf.keep() is
                    // used to extract training inputs.
                    layer.setCallHook(function logInputs(inputs) {
                        if (!Array.isArray(inputs)) {
                            inputs = [inputs];
                        }
                        for (let i = 0; i < inputs.length; ++i) {
                            const input = inputs[i].flatten();
                            let name = `${layer.name}/input`;
                            if (inputs.length > 1) {
                                name += `/${i}`;
                            }
                            (hookedInputs[name] ??= []).push(tf.keep(input));
                        }
                    });
                }
            }

            const {value: loss, grads} = this.optimizer.computeGradients(
                () => this.loss(batch.state, batch.action, target),
                this.variables,
            );
            this.optimizer.applyGradients(grads);

            const postStep = process.hrtime.bigint();
            const updateMs = Number(postStep - preStep) / 1e6;
            this.metrics?.scalar("update_ms", updateMs, step);
            this.metrics?.scalar(
                "update_throughput_s",
                this.config.batchSize /
                    (updateMs / 1e3) /*experiences per sec*/,
                step,
            );

            this.metrics?.scalar("loss", loss, step);
            if (storeBatchMetrics) {
                for (const name in grads) {
                    if (Object.prototype.hasOwnProperty.call(grads, name)) {
                        const grad = grads[name];
                        if (grad.size === 1) {
                            this.metrics?.scalar(
                                `${name}/grads`,
                                grad.asScalar(),
                                step,
                            );
                        } else {
                            this.metrics?.histogram(
                                `${name}/grads`,
                                grad,
                                step,
                            );
                        }
                    }
                }

                for (const name in hookedInputs) {
                    if (
                        Object.prototype.hasOwnProperty.call(hookedInputs, name)
                    ) {
                        this.metrics?.histogram(
                            name,
                            tf.concat1d(hookedInputs[name]),
                            step,
                        );
                    }
                }
                tf.dispose(hookedInputs);

                for (const weights of this.variables) {
                    if (weights.size === 1) {
                        this.metrics?.scalar(
                            `${weights.name}/weights`,
                            weights.asScalar(),
                            step,
                        );
                    } else {
                        this.metrics?.histogram(
                            `${weights.name}/weights`,
                            weights,
                            step,
                        );
                    }
                }

                for (const layer of this.hookLayers) {
                    layer.clearCallHook();
                }
            }

            return loss;
        });
    }

    /** Calculates TD target for an experience batch. */
    private calculateTarget(
        reward: tf.Tensor,
        nextState: tf.Tensor[],
        done: tf.Tensor,
    ): tf.Tensor {
        return tf.tidy(() => {
            let targetQ: tf.Tensor;
            const q = this.model.predictOnBatch(nextState) as tf.Tensor;
            if (!this.config.target) {
                // Vanilla DQN TD target: r + gamma * max_a(Q(s', a))
                targetQ = tf.max(q, -1);
            } else {
                targetQ = this.targetModel.predictOnBatch(
                    nextState,
                ) as tf.Tensor;
                if (this.config.target !== "double") {
                    // TD target with target net: r + gamma * max_a(Qt(s', a))
                    targetQ = tf.max(targetQ, -1);
                } else {
                    // Double Q target: r + gamma * Qt(s', argmax_a(Q(s', a)))
                    const action = tf.argMax(q, -1);
                    const actionMask = tf.oneHot(action, intToChoice.length);
                    targetQ = tf.sum(tf.mul(targetQ, actionMask), -1);
                }
            }

            // Also mask out q values of terminal states.
            targetQ = tf.where(done, 0, targetQ);

            const target = tf.add(
                reward,
                tf.mul(this.expConfig.rewardDecay, targetQ),
            );
            return target;
        });
    }

    /** Calculates training loss on an experience batch. */
    private loss(
        state: tf.Tensor[],
        action: tf.Tensor,
        target: tf.Tensor,
    ): tf.Scalar {
        return tf.tidy("loss", () => {
            let q = this.model.predictOnBatch(state) as tf.Tensor;
            const mask = tf.oneHot(action, intToChoice.length);
            q = tf.sum(tf.mul(q, mask), -1);
            return tf.losses.meanSquaredError(target, q);
        });
    }

    /** Cleans up dangling variables. */
    public cleanup(): void {
        this.optimizer.dispose();
        Metrics.flush();
    }
}
